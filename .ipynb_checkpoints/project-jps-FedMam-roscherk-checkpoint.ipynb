{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы сокращения пространства поиска на графе регулярной декомпозиции за счет симметрии и смежных техник (JPS и его модификации).\n",
    "\n",
    "_Федор Мамаев, Прохор Архипов, 22Б09_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: написать какую-то очень умную воду"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./img/1.png\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import traceback\n",
    "import time\n",
    "import sys\n",
    "import asyncio\n",
    "from heapq import heappop, heappush\n",
    "from pathlib import Path\n",
    "from textwrap import dedent\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "rand = random.Random(192837)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Представление карты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell:\n",
    "    def __init__(self, i: int, j: int):\n",
    "        self._i = i\n",
    "        self._j = j\n",
    "    \n",
    "    @property\n",
    "    def i(self):\n",
    "        return self._i\n",
    "    \n",
    "    @property\n",
    "    def j(self):\n",
    "        return self._j\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, Cell) and (self._i, self._j) == (other._i, other._j)\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self._i, self._j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Direction:\n",
    "    def __init__(self, di: int, dj: int):\n",
    "        self._di = di\n",
    "        self._dj = dj\n",
    "    \n",
    "    @property\n",
    "    def di(self):\n",
    "        return self._di\n",
    "    \n",
    "    @property\n",
    "    def dj(self):\n",
    "        return self._dj\n",
    "    \n",
    "    @property\n",
    "    def delta(self):\n",
    "        return (self._di, self._dj)\n",
    "    \n",
    "    @property\n",
    "    def is_diagonal(self):\n",
    "        return self._di != 0 and self._dj != 0\n",
    "    \n",
    "    def reversed(self):\n",
    "        return Direction(-self._di, -self._dj)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, Direction) and self.delta == other.delta\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.delta)\n",
    "\n",
    "Direction.NONE = Direction(0, 0)\n",
    "Direction.DOWN = Direction(1, 0)\n",
    "Direction.RIGHT = Direction(0, 1)\n",
    "Direction.UP = Direction(-1, 0)\n",
    "Direction.LEFT = Direction(0, -1)\n",
    "Direction.DIAG_DR = Direction(1, 1)\n",
    "Direction.DIAG_UR = Direction(-1, 1)\n",
    "Direction.DIAG_DL = Direction(1, -1)\n",
    "Direction.DIAG_UL = Direction(-1, -1)\n",
    "Direction.ALL_DIRECTIONS = [\n",
    "    Direction.DOWN,\n",
    "    Direction.RIGHT,\n",
    "    Direction.UP,\n",
    "    Direction.LEFT,\n",
    "    Direction.DIAG_DR,\n",
    "    Direction.DIAG_UR,\n",
    "    Direction.DIAG_DL,\n",
    "    Direction.DIAG_UL,\n",
    "]\n",
    "\n",
    "def direction_from_to(a: Cell, b: Cell):\n",
    "    return Direction(b.i - a.i, b.j - a.j)\n",
    "\n",
    "def step(cell: Cell, d: Direction):\n",
    "    return Cell(cell.i + d.di, cell.j + d.dj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Map:\n",
    "    def __init__(self, cells: npt.NDArray):\n",
    "        self._width = cells.shape[1]\n",
    "        self._height = cells.shape[0]\n",
    "        self._cells = cells\n",
    "\n",
    "    def in_bounds(self, cell: Cell) -> bool:\n",
    "        return 0 <= cell.j < self._width and 0 <= cell.i < self._height\n",
    "\n",
    "    def traversable(self, cell: Cell) -> bool:\n",
    "        return self.in_bounds(cell) and not self._cells[cell.i, cell.j]\n",
    "\n",
    "    def get_neighbours(self, cell: Cell) -> List[Cell]:\n",
    "        neighbours = []\n",
    "        \n",
    "        i = cell.i\n",
    "        j = cell.j\n",
    "\n",
    "        # срезание углов разрешено\n",
    "        for d in Direction.ALL_DIRECTIONS:\n",
    "            next = step(cell, d)\n",
    "            if self.traversable(next):\n",
    "                neighbours.append(next)\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "    @property\n",
    "    def size(self) -> Tuple[int, int]:\n",
    "        return (self._height, self._width)\n",
    "    \n",
    "    @property\n",
    "    def height(self) -> int:\n",
    "        return self._height\n",
    "    \n",
    "    @property\n",
    "    def width(self) -> int:\n",
    "        return self._width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(a: Cell, b: Cell) -> Union[int, float]:\n",
    "    if abs(a.i - b.i) + abs(a.j - b.j) == 1:  # Cardinal move\n",
    "        return 1\n",
    "    elif abs(a.i - b.i) == 1 and abs(a.j - b.j) == 1:\n",
    "        return math.sqrt(2)\n",
    "    else:\n",
    "        raise ValueError(\"Trying to compute the cost of a non-supported move! ONLY cardinal and diagonal moves are supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вершина поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        cell: Cell,\n",
    "        g: Union[float, int] = 0,\n",
    "        h: Union[float, int] = 0,\n",
    "        f: Optional[Union[float, int]] = None,\n",
    "        parent: \"Node\" = None,\n",
    "    ):\n",
    "        self.cell = cell\n",
    "        self.g = g\n",
    "        self.h = h\n",
    "        if f is None:\n",
    "            self.f = self.g + h\n",
    "        else:\n",
    "            self.f = f\n",
    "        self.parent = parent\n",
    "\n",
    "    @property\n",
    "    def i(self):\n",
    "        return self.cell.i\n",
    "    \n",
    "    @property\n",
    "    def j(self):\n",
    "        return self.cell.j\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.cell == other.cell\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.cell) ^ 0x19283746\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return (self.f < other.f) or (self.f == other.f and self.h < other.h)  # лучший tie-break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Дерево поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchTreePQD:\n",
    "    def __init__(self):\n",
    "        self._open = []\n",
    "        self._closed = {}\n",
    "        self._enc_open_duplicates = 0\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._open) + len(self._closed)\n",
    "\n",
    "    def open_is_empty(self) -> bool:\n",
    "        return len(self._open) == 0\n",
    "\n",
    "    def add_to_open(self, item: Node):\n",
    "        heappush(self._open, item)\n",
    "\n",
    "    def get_best_node_from_open(self) -> Optional[Node]:\n",
    "        while not self.open_is_empty() and self.was_expanded(self._open[0]):\n",
    "            self._enc_open_duplicates += 1\n",
    "            heappop(self._open)\n",
    "        if self.open_is_empty():\n",
    "            return None\n",
    "        return heappop(self._open)\n",
    "        \n",
    "    def add_to_closed(self, item: Node):\n",
    "        self._closed[item.cell] = item\n",
    "\n",
    "    def was_expanded(self, item: Node) -> bool:\n",
    "        return item.cell in self._closed\n",
    "\n",
    "    @property\n",
    "    def opened(self):\n",
    "        return self._open\n",
    "\n",
    "    @property\n",
    "    def expanded(self):\n",
    "        return self._closed.values()\n",
    "\n",
    "    @property\n",
    "    def number_of_open_duplicates(self):\n",
    "        return self._enc_open_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Валидация результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_path(goal: Optional[Node]) -> Tuple[Optional[List[Node]], Union[float, int]]:\n",
    "    if goal is None:\n",
    "        return None, 0\n",
    "\n",
    "    length = goal.g\n",
    "    current = goal\n",
    "    path = []\n",
    "    while current.parent:\n",
    "        path.append(current)\n",
    "        current = current.parent\n",
    "    path.append(current)\n",
    "    return path[::-1], length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Чтение заданий из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task:\n",
    "    # TODO: пока optimal_dist читается из файла, но в дальнейшем\n",
    "    # нужно придумать, как оценивать его с помощью стандартного A*,\n",
    "    # не делая это два раза\n",
    "    def __init__(self, bucket: int, map: Map, start: Cell, goal: Cell, optimal_dist: float):\n",
    "        self.bucket = bucket\n",
    "        self.map = map\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "        self.optimal_dist = optimal_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_map_from_file(filename: str) -> Map:\n",
    "    with open(filename, 'r') as file:\n",
    "        file.readline()                           # type octile\n",
    "        height = int(file.readline().strip().split()[1])  # height XX\n",
    "        width  = int(file.readline().strip().split()[1])  # width YY\n",
    "        file.readline()                           # map\n",
    "\n",
    "        map = np.ndarray(shape=(height, width), dtype=np.dtypes.BoolDType)\n",
    "        for i in range(height):\n",
    "            row = file.readline()\n",
    "            for j in range(width):\n",
    "                map[i, j] = row[j] in ['@', 'O', 'T']\n",
    "        \n",
    "        return Map(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_storage: Dict[str, Map] = {}\n",
    "\n",
    "def get_map(filename: str) -> Map:\n",
    "    if filename not in map_storage:\n",
    "        map_storage[filename] = read_map_from_file(f'./tasks/maps/{filename}')\n",
    "    return map_storage[filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_scenario_from_file(filename: str) -> List[Task]:\n",
    "    tasks = []\n",
    "    with open(filename, 'r') as file:\n",
    "        file.readline()  # version x.x\n",
    "\n",
    "        for line in file.readlines():\n",
    "            bucket_s, map_name, height_s, width_s, start_j_s, start_i_s, goal_j_s, goal_i_s, optimal_dist_s = line.strip().split('\\t')\n",
    "            map = get_map(map_name)\n",
    "            tasks.append(Task(\n",
    "                int(bucket_s),\n",
    "                map,\n",
    "                Cell(int(start_i_s), int(start_j_s)),\n",
    "                Cell(int(goal_i_s), int(goal_j_s)),\n",
    "                float(optimal_dist_s)\n",
    "            ))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Параметры алгоритма A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# типы\n",
    "\n",
    "HeuristicFunc = Callable[[Cell, Cell], float]\n",
    "NeighboursFunc = Callable[[Node, Map, Cell, HeuristicFunc], List[Node]]  # curr node, map, goal, heuristic -> neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_octile(a: Cell, b: Cell):\n",
    "    dr = max(abs(a.i - b.i), abs(a.j - b.j))\n",
    "    dl = min(abs(a.i - b.i), abs(a.j - b.j))\n",
    "    return (dr - dl) + dl * math.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_heuristic(heuristic_func: HeuristicFunc, weight: float) -> HeuristicFunc:\n",
    "    return lambda a, b: heuristic_func(a, b) * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours_all(curr_node: Node, map: Map, goal: Cell, heuristic_func: HeuristicFunc):\n",
    "    return [\n",
    "        Node(\n",
    "            cell=next_cell,\n",
    "            g=curr_node.g + compute_cost(curr_node.cell, next_cell),\n",
    "            h=heuristic_func(next_cell, goal),\n",
    "            parent=curr_node\n",
    "        )\n",
    "        for next_cell in map.get_neighbours(curr_node.cell)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Функция поиска точек прыжка для алгоритма JPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можем ли мы повернуть в соответствии с Canonical Ordering\n",
    "def can_turn(curr_d: Direction, next_d: Direction):\n",
    "    if curr_d == next_d:\n",
    "        return True\n",
    "    if curr_d.is_diagonal and \\\n",
    "       (next_d.delta == (curr_d.di, 0) or \\\n",
    "        next_d.delta == (0, curr_d.dj)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# направление первого шага от a к b согласно canonical ordering\n",
    "def canonical_direction_from_to(a: Cell, b: Cell):\n",
    "    d = direction_from_to(a, b)\n",
    "    d = Direction((d.di // abs(d.di) if d.di != 0 else 0),\n",
    "                  (d.dj // abs(d.dj) if d.dj != 0 else 0))\n",
    "    return d\n",
    "\n",
    "# см. статью\n",
    "def get_forced_neighbours(curr_cell: Cell, map: Map, d: Direction):\n",
    "    parent_cell = step(curr_cell, d.reversed())\n",
    "    return [\n",
    "        next_cell\n",
    "        for next_cell in map.get_neighbours(curr_cell)\n",
    "        if canonical_direction_from_to(parent_cell, next_cell) != d and \\\n",
    "           not map.traversable(step(parent_cell, canonical_direction_from_to(parent_cell, next_cell)))\n",
    "    ]\n",
    "\n",
    "def jps_jump(curr_node: Node, map: Map, d: Direction, goal: Cell, heuristic_func: HeuristicFunc, bound: Optional[int]) -> Optional[Node]:\n",
    "    curr_cell = curr_node.cell\n",
    "    next_cell = step(curr_cell, d)\n",
    "\n",
    "    if not map.traversable(next_cell):\n",
    "        return None\n",
    "    \n",
    "    next_node = Node(\n",
    "        cell=next_cell,\n",
    "        g=curr_node.g + compute_cost(curr_cell, next_cell),\n",
    "        h=heuristic_func(next_cell, goal),\n",
    "        parent=curr_node\n",
    "    )\n",
    "\n",
    "    if next_cell == goal:\n",
    "        return next_node\n",
    "    if bound is not None and bound == 0:\n",
    "        return next_node\n",
    "    \n",
    "    if len(get_forced_neighbours(next_cell, map, d)) != 0:\n",
    "        return next_node\n",
    "    \n",
    "    if d.is_diagonal:\n",
    "        for d_proj in (Direction(d.di, 0), Direction(0, d.dj)):\n",
    "            if jps_jump(next_node, map, d_proj, goal, heuristic_func, (bound - 1) if bound is not None else None) is not None:\n",
    "                return next_node\n",
    "\n",
    "    return jps_jump(next_node, map, d, goal, heuristic_func, (bound - 1) if bound is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# направления для раскрытия в соответствии с full canonical ordering\n",
    "def canonical_directions_for_expansion(curr_node: Node, map: Map):\n",
    "    if curr_node.parent is None:\n",
    "        return Direction.ALL_DIRECTIONS\n",
    "    \n",
    "    d = direction_from_to(curr_node.parent.cell, curr_node.cell)\n",
    "    if len(get_forced_neighbours(curr_node.cell, map, d)) != 0:\n",
    "        return Direction.ALL_DIRECTIONS\n",
    "    if d.is_diagonal:\n",
    "        return [d, Direction(d.di, 0), Direction(0, d.dj)]\n",
    "    return [d]\n",
    "\n",
    "def jps_generate_neighbours(curr_node: Node, map: Map, goal: Cell, heuristic_func: HeuristicFunc, bound: Optional[int]) -> List[Node]:\n",
    "    return list(filter(lambda it: it is not None, [\n",
    "        jps_jump(curr_node, map, d, goal, heuristic_func, bound)\n",
    "        for d in canonical_directions_for_expansion(curr_node, map)\n",
    "    ]))\n",
    "\n",
    "def neighbours_bounded_jps(bound: int) -> NeighboursFunc:\n",
    "    return lambda curr_node, map, goal, heuristic_func: jps_generate_neighbours(\n",
    "        curr_node, map, goal, heuristic_func, bound\n",
    "    )\n",
    "\n",
    "neighbours_canonical_astar = neighbours_bounded_jps(0)\n",
    "neighbours_jps = neighbours_bounded_jps(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Алгоритм A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_search(\n",
    "    task_map: Map,\n",
    "    start: Cell,\n",
    "    goal: Cell,\n",
    "    heuristic_func: HeuristicFunc,\n",
    "    neighbours_func: NeighboursFunc,\n",
    "    search_tree: Type[SearchTreePQD],\n",
    ") -> Tuple[bool, Optional[Node], int, int, int]:\n",
    "    # Returns: found or not, final node, steps, tree size\n",
    "    ast = search_tree()\n",
    "    steps = 0\n",
    "\n",
    "    start_node = Node(cell=start, g=0, h=heuristic_func(start, goal))\n",
    "    ast.add_to_open(start_node)\n",
    "\n",
    "    while not ast.open_is_empty():\n",
    "        curr_node: Node = ast.get_best_node_from_open()\n",
    "        if curr_node is None:\n",
    "            break\n",
    "        curr_cell: Cell = curr_node.cell\n",
    "        ast.add_to_closed(curr_node)\n",
    "\n",
    "        if curr_cell == goal:\n",
    "            return True, curr_node, steps, len(ast)\n",
    "\n",
    "        steps += 1\n",
    "        for next_node in neighbours_func(curr_node, task_map, goal, heuristic_func):\n",
    "            if not ast.was_expanded(next_node):\n",
    "                ast.add_to_open(next_node)\n",
    "\n",
    "    return False, None, steps, len(ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "AstarAlgorithm = Callable[[Map, Cell, Cell], Tuple[bool, Optional[Node], int, int, int]]\n",
    "\n",
    "standard_astar  = lambda map, start, goal: astar_search(map, start, goal, heuristic_octile, neighbours_all, SearchTreePQD)\n",
    "canonical_astar = lambda map, start, goal: astar_search(map, start, goal, heuristic_octile, neighbours_canonical_astar, SearchTreePQD)\n",
    "jps             = lambda map, start, goal: astar_search(map, start, goal, heuristic_octile, neighbours_jps, SearchTreePQD)\n",
    "\n",
    "def weighted_astar(weight: float):\n",
    "    return lambda map, start, goal: astar_search(\n",
    "        map, start, goal, weighted_heuristic(heuristic_octile, weight), neighbours_all, SearchTreePQD\n",
    "    )\n",
    "def weighted_jps(weight: float):\n",
    "    return lambda map, start, goal: astar_search(\n",
    "        map, start, goal, weighted_heuristic(heuristic_octile, weight), neighbours_jps, SearchTreePQD\n",
    "    )\n",
    "def bounded_jps(bound: int):\n",
    "    return lambda map, start, goal: astar_search(\n",
    "        map, start, goal, heuristic_octile, neighbours_bounded_jps(bound), SearchTreePQD\n",
    "    )\n",
    "def weighted_bounded_jps(weight: float, bound: int):\n",
    "    return lambda map, start, goal: astar_search(\n",
    "        map, start, goal, weighted_heuristic(heuristic_octile, weight), neighbours_bounded_jps(bound), SearchTreePQD\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Давайте проведём бенчмаркинг\n",
    "\n",
    "TODO: написать ещё какую-нибудь умную воду (вообще её надо написать везде, где только можно)\n",
    "\n",
    "Все карты скачаны с https://movingai.com/benchmarks/grids.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./img/2.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.0. Полезные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_on_task(\n",
    "    task: Task, algorithm: AstarAlgorithm\n",
    ") -> Tuple[bool, Optional[List[Node]], float, int, int, float]:\n",
    "    # Returns: found o/n, result path, path length, steps, tree size, time\n",
    "    start_time = time.time()\n",
    "    found, final_node, steps, tree_size = algorithm(\n",
    "        task.map,\n",
    "        task.start,\n",
    "        task.goal\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    result_path, path_length = make_path(final_node)\n",
    "    return found, result_path, path_length, steps, tree_size, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_on_tasks(\n",
    "    tasks: List[Task],\n",
    "    algorithms: List[Tuple[str, AstarAlgorithm]],\n",
    "    show_info: bool = True,\n",
    "    progressbar_length: int = 50\n",
    ") -> Dict[str, Tuple[np.array, np.array, np.array, np.array]]:\n",
    "    summary = {\n",
    "        alg_name: ([], [], [], [], []) for alg_name, _ in algorithms\n",
    "    }\n",
    "\n",
    "    tasks_num = len(tasks)\n",
    "    tasks_completed = 0\n",
    "    progress_units_completed = 0\n",
    "    if show_info:\n",
    "        print(' ' + '_' * progressbar_length + ' ')\n",
    "        print('[', end='')\n",
    "\n",
    "    async_loop = asyncio.new_event_loop()\n",
    "    async_tasks = {\n",
    "        alg_name: [] for alg_name, _ in algorithms\n",
    "    }\n",
    "    for task in tasks:\n",
    "        for alg_name, algorithm in algorithms:\n",
    "            async_tasks[alg_name].append(async_loop.create_task(run_on_task(task, algorithm)))\n",
    "\n",
    "    for i in range(len(tasks)):\n",
    "        for alg_name, algorithm in algorithms:\n",
    "            _, _, path_length, steps, tree_size, time_spent = await async_tasks[alg_name][i]\n",
    "            optimality = path_length / tasks[i].optimal_dist\n",
    "            summary[alg_name][0].append(optimality)\n",
    "            summary[alg_name][1].append(path_length)\n",
    "            summary[alg_name][2].append(tree_size)\n",
    "            summary[alg_name][3].append(steps)\n",
    "            summary[alg_name][4].append(time_spent)\n",
    "        \n",
    "        tasks_completed += 1\n",
    "        if show_info:\n",
    "            while tasks_completed >= int(tasks_num / progressbar_length * (progress_units_completed + 1)) and progress_units_completed < progressbar_length:\n",
    "                progress_units_completed += 1\n",
    "                print('|', end='')\n",
    "                sys.stdout.flush()\n",
    "    \n",
    "    if show_info:\n",
    "        print(']')\n",
    "    \n",
    "    return {\n",
    "        alg_name: tuple(map(lambda lst: np.array(lst), summary[alg_name]))\n",
    "        for alg_name in summary.keys()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary(summary: Dict[str, Tuple[np.array, np.array, np.array, np.array, np.array]], bar_color: str):\n",
    "    algorithm_names = list(summary.keys())\n",
    "\n",
    "    optimality_data = [\n",
    "        np.array(summary[alg_name][0]) * 100\n",
    "        for alg_name in algorithm_names\n",
    "    ]\n",
    "    length_data = [\n",
    "        summary[alg_name][1]\n",
    "        for alg_name in algorithm_names\n",
    "    ]\n",
    "    tree_size_data = [\n",
    "        summary[alg_name][2]\n",
    "        for alg_name in algorithm_names\n",
    "    ]\n",
    "    steps_data = [\n",
    "        summary[alg_name][3]\n",
    "        for alg_name in algorithm_names\n",
    "    ]\n",
    "    time_data = [\n",
    "        summary[alg_name][4]\n",
    "        for alg_name in algorithm_names\n",
    "    ]\n",
    "    optimality_avg = [\n",
    "        float(np.mean(summary[alg_name][0])) * 100\n",
    "        for alg_name in algorithm_names\n",
    "    ]\n",
    "    length_avg = [\n",
    "        float(np.mean(summary[alg_name][1]))\n",
    "        for alg_name in algorithm_names\n",
    "    ]\n",
    "    tree_size_avg = [\n",
    "        float(np.mean(summary[alg_name][2]))\n",
    "        for alg_name in algorithm_names\n",
    "    ]\n",
    "    steps_avg = [\n",
    "        float(np.mean(summary[alg_name][3]))\n",
    "        for alg_name in algorithm_names\n",
    "    ]\n",
    "    time_avg = [\n",
    "        float(np.mean(summary[alg_name][4]))\n",
    "        for alg_name in algorithm_names\n",
    "    ]\n",
    "\n",
    "    print('===== SUMMARY =====')\n",
    "    print('=== Average optimality ratio: ===')\n",
    "    print('\\n'.join(['Weight = %s: %d%%' % it for it in zip(algorithm_names, map(int, optimality_avg))]))\n",
    "    print('=== Average path length: ===')\n",
    "    print('\\n'.join(['Weight = %s: %.6f' % it for it in zip(algorithm_names, length_avg)]))\n",
    "    print('=== Average search tree size: ===')\n",
    "    print('\\n'.join(['Weight = %s: %d' % it for it in zip(algorithm_names, tree_size_avg)]))\n",
    "    print('=== Average expansions: ===')\n",
    "    print('\\n'.join(['Weight = %s: %d' % it for it in zip(algorithm_names, steps_avg)]))\n",
    "    print('=== Average time usage: ===')\n",
    "    print('\\n'.join(['Weight = %s: %.4f s' % it for it in zip(algorithm_names, time_avg)]))\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(12, 12))\n",
    "    ((ax_opbw, ax_opa), (ax_lnbw, ax_lna), (ax_tsbw, ax_tsa), (ax_exbw, ax_exa), (ax_tmbw, ax_tma)) = axs\n",
    "    ax_opbw.set_title('Cost Overhead (%)')\n",
    "    ax_lnbw.set_title('Path Length')\n",
    "    ax_tsbw.set_title('Search Tree Size')\n",
    "    ax_exbw.set_title('Expansions')\n",
    "    ax_tmbw.set_title('Time Spent (s)')\n",
    "    ax_opa.set_title('Average Cost Overhead (%)')\n",
    "    ax_lna.set_title('Average Path Length')\n",
    "    ax_tsa.set_title('Average Search Tree Size')\n",
    "    ax_exa.set_title('Average Expansions')\n",
    "    ax_tma.set_title('Average Time (s)')\n",
    "\n",
    "    boxplots = [\n",
    "        ax_opbw.boxplot(optimality_data, tick_labels=algorithm_names, patch_artist=True),\n",
    "        ax_lnbw.boxplot(length_data,     tick_labels=algorithm_names, patch_artist=True),\n",
    "        ax_tsbw.boxplot(tree_size_data,  tick_labels=algorithm_names, patch_artist=True),\n",
    "        ax_exbw.boxplot(steps_data,      tick_labels=algorithm_names, patch_artist=True),\n",
    "        ax_tmbw.boxplot(time_data,       tick_labels=algorithm_names, patch_artist=True)\n",
    "    ]\n",
    "    \n",
    "    for boxplot in boxplots:\n",
    "        for patch in boxplot['boxes']:\n",
    "            patch.set_facecolor(bar_color)\n",
    "    \n",
    "    barplots = [\n",
    "        ax_opa.bar(algorithm_names, optimality_avg, color=bar_color),\n",
    "        ax_lna.bar(algorithm_names, length_avg,     color=bar_color),\n",
    "        ax_tsa.bar(algorithm_names, tree_size_avg,  color=bar_color),\n",
    "        ax_exa.bar(algorithm_names, steps_avg,      color=bar_color),\n",
    "        ax_tma.bar(algorithm_names, time_avg,       color=bar_color)\n",
    "    ]\n",
    "\n",
    "    for ax in axs[:, 0]:\n",
    "        ax.set_xticks(range(1, 1 + len(algorithm_names)))\n",
    "        ax.set_xticklabels(algorithm_names, rotation=45)\n",
    "    for ax in axs[:, 1]:\n",
    "        ax.set_xticks(range(len(algorithm_names)))\n",
    "        ax.set_xticklabels(algorithm_names, rotation=45)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. Список алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: убрать и написать там. Примечание:\n",
    "Здесь из списка заданий будет выбираться случайным образом 500 и делиться по уровням сложности. Первые 250 -- Easy, следующие 150 -- Normal, следующие 75 -- Hard, последние 25 -- Brutal. Оцениваться будут стандартным A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_algorithm = ('A*', standard_astar)\n",
    "all_algorithms = [\n",
    "    optimal_algorithm,\n",
    "    ('Canonical A*', canonical_astar),\n",
    "    ('BJPS (bound = 1)', bounded_jps(1)),\n",
    "    ('BJPS (bound = 4)', bounded_jps(4)),\n",
    "    ('BJPS (bound = 16)', bounded_jps(16)),\n",
    "    ('BJPS (bound = 64)', bounded_jps(64)),\n",
    "    ('JPS', jps),\n",
    "    ('WA* (W = 1.2)', weighted_astar(1.2)),\n",
    "    ('WJPS (W = 1.2)', weighted_jps(1.2)),\n",
    "    ('WA* (W = 2)', weighted_astar(2)),\n",
    "    ('WJPS (W = 2)', weighted_jps(2)),\n",
    "    ('WA* (W = 5)', weighted_astar(5)),\n",
    "    ('WJPS (W = 5)', weighted_jps(5)),\n",
    "    ('WBJPS (W = 2, bound = 16)', weighted_bounded_jps(2, 16))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of tasks per difficulty level\n",
    "EASY_NUM = 250\n",
    "MEDIUM_NUM = 150\n",
    "HARD_NUM = 75\n",
    "BRUTAL_NUM = 25\n",
    "TASK_NUM = EASY_NUM + MEDIUM_NUM + HARD_NUM + BRUTAL_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_scenarios(scenario_filenames: List[str]):\n",
    "    tasks: List[Task] = []\n",
    "\n",
    "    for scen_fn in scenario_filenames:\n",
    "        tasks += read_scenario_from_file(f'tasks/scenarios/{scen_fn}')\n",
    "    \n",
    "    while len(tasks) > TASK_NUM:\n",
    "        del tasks[rand.randint(0, len(tasks) - 1)]\n",
    "\n",
    "    print(f'Running A* on tasks to estimate difficulty level...')\n",
    "    optimal_path_length = (await run_on_tasks(tasks, [optimal_algorithm]))[optimal_algorithm[0]][1]\n",
    "    for i in range(len(tasks)):\n",
    "        tasks[i].optimal_dist = optimal_path_length[i]\n",
    "    tasks = sorted(tasks, key=lambda task: task.optimal_dist)\n",
    "\n",
    "    tasks_easy = tasks[: EASY_NUM]\n",
    "    tasks_medm = tasks[EASY_NUM : EASY_NUM + MEDIUM_NUM]\n",
    "    tasks_hard = tasks[EASY_NUM + MEDIUM_NUM : EASY_NUM + MEDIUM_NUM + HARD_NUM]\n",
    "    tasks_shrd = tasks[EASY_NUM + MEDIUM_NUM + HARD_NUM :]\n",
    "\n",
    "    if len(tasks_easy) > 0:\n",
    "        print(f'Running tests on Easy tasks, {len(tasks_easy)} tasks total...')\n",
    "        plot_summary(await run_on_tasks(tasks_easy, all_algorithms), 'Green')\n",
    "    else:\n",
    "        print(f'No Easy tasks found in the scenarios')\n",
    "    if len(tasks_medm) > 0:\n",
    "        print(f'Running tests on Medium tasks, {len(tasks_medm)} tasks total...')\n",
    "        plot_summary(await run_on_tasks(tasks_medm, all_algorithms), 'Orange')\n",
    "    else:\n",
    "        print(f'No Medium tasks found in the scenarios')\n",
    "    if len(tasks_hard) > 0:\n",
    "        print(f'Running tests on Hard tasks, {len(tasks_hard)} tasks total...')\n",
    "        plot_summary(await run_on_tasks(tasks_hard, all_algorithms), 'Red')\n",
    "    else:\n",
    "        print(f'No Hard tasks found in the scenarios')\n",
    "    if len(tasks_shrd) > 0:\n",
    "        print(f'Running tests on Brutal tasks, {len(tasks_shrd)} tasks total...')\n",
    "        plot_summary(await run_on_tasks(tasks_shrd, all_algorithms), '#66023c')\n",
    "    else:\n",
    "        print(f'No Brutal tasks found in the scenarios')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Карты городов 1024x1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city1024_scenarios = [\n",
    "    'Berlin_1_1024.map.scen',\n",
    "    'Milan_1_1024.map.scen',\n",
    "    'Moscow_0_1024.map.scen',\n",
    "    'Shanghai_0_1024.map.scen'\n",
    "]\n",
    "\n",
    "test_on_scenarios(city1024_scenarios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
